"""
CHAIN.PY - TUTKU SUPPLY CHAIN DATASET Ä°Ã‡Ä°N RAG SÄ°STEMÄ°
"""

import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.schema import Document
from langchain.chains import RetrievalQA

from config import GEMINI_API_KEY, CHUNK_SIZE, CHUNK_OVERLAP, MODEL_NAME, VECTOR_DB_PATH
from data_loader import load_tutku_supply_chain_data  # Ã–ZEL: Tutku dataset loader

class SupplyChainChatbot:
    def __init__(self):
        """Chatbot'u baÅŸlat"""
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=GEMINI_API_KEY
        )
        self.llm = ChatGoogleGenerativeAI(
            model=MODEL_NAME,
            google_api_key=GEMINI_API_KEY,
            temperature=0.3
        )
        self.vector_store = None
        self.qa_chain = None
        
    def load_and_process_data(self):
        """TUTKU Ã–ZDENÄ°Z DATASET'Ä°NÄ° YÃœKLE"""
        print("ğŸ“š Tutku Ã–zdeniz supply chain dataset'i yÃ¼kleniyor...")
        
        # Ã–ZEL: Tutku dataset'ini yÃ¼kle
        documents = load_tutku_supply_chain_data()
        
        if not documents:
            print("âŒ HiÃ§ veri yÃ¼klenemedi, demo veri kullanÄ±lÄ±yor...")
            documents = [Document(
                page_content="Supply Chain Management: Tedarik zinciri yÃ¶netimi temel kavramlarÄ±.",
                metadata={"source": "demo_data"}
            )]
        
        # PDF'ler iÃ§in optimize edilmiÅŸ bÃ¶lÃ¼cÃ¼
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""]  # PDF metinleri iÃ§in
        )
        chunks = text_splitter.split_documents(documents)
        
        print(f"âœ… {len(chunks)} metin parÃ§asÄ± oluÅŸturuldu")
        return chunks
    
    def setup_vector_store(self, chunks):
        """VektÃ¶r veritabanÄ±nÄ± oluÅŸtur"""
        print("ğŸ—„ï¸ VektÃ¶r veritabanÄ± oluÅŸturuluyor...")
        
        self.vector_store = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=VECTOR_DB_PATH
        )
        print("âœ… VektÃ¶r veritabanÄ± hazÄ±r")
    
    def setup_qa_chain(self):
        """Soru-cevap zincirini kur"""
        print("ğŸ”— QA zinciri kuruluyor...")
        
        retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4}  # PDF'ler iÃ§in daha fazla kaynak
        )
        
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            verbose=False
        )
        print("âœ… QA zinciri hazÄ±r")
    
    def initialize_chatbot(self):
        """TÃ¼m sistemi baÅŸlat"""
        print("ğŸ¤– Supply Chain Chatbot baÅŸlatÄ±lÄ±yor...")
        
        chunks = self.load_and_process_data()
        self.setup_vector_store(chunks)
        self.setup_qa_chain()
        
        print("ğŸ‰ Chatbot hazÄ±r! SorularÄ±nÄ±zÄ± bekliyorum...")
    
    def ask_question(self, question):
        """KullanÄ±cÄ± sorusuna cevap ver"""
        if not self.qa_chain:
            return "âŒ Chatbot henÃ¼z hazÄ±r deÄŸil."
        
        try:
            response = self.qa_chain({"query": question})
            answer = response["result"]
            source_docs = response["source_documents"]
            
            # KaynaklarÄ± gÃ¶ster (PDF dosya isimleriyle)
            sources = "\n\nğŸ“š Kaynak Dosyalar:\n"
            for i, doc in enumerate(source_docs[:3]):
                filename = doc.metadata.get('filename', 'Bilinmeyen dosya')
                source_type = doc.metadata.get('type', 'pdf')
                preview = doc.page_content[:100].replace('\n', ' ') + "..."
                
                sources += f"{i+1}. ğŸ“„ {filename} ({source_type})\n"
                sources += f"   Ã–nizleme: {preview}\n\n"
            
            return answer + sources
            
        except Exception as e:
            return f"âŒ Hata oluÅŸtu: {str(e)}"

# Test
if __name__ == "__main__":
    chatbot = SupplyChainChatbot()
    chatbot.initialize_chatbot()
    
    # Test sorularÄ±
    test_questions = [
        "Supply chain management nedir?",
        "Tedarik zinciri optimizasyonu nasÄ±l yapÄ±lÄ±r?",
        "Lojistik yÃ¶netimi hakkÄ±nda bilgi ver"
    ]
    
    for question in test_questions:
        print(f"\nğŸ§ª Soru: {question}")
        print("â”€" * 50)
        print(chatbot.ask_question(question))
